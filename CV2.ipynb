{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32213342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de814864",
   "metadata": {},
   "source": [
    "Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db19bb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('text.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d348ca",
   "metadata": {},
   "source": [
    "Convert to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cbb8bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba87f4af",
   "metadata": {},
   "source": [
    "Apply threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5e951fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = cv2.threshold(gray, 150,255, cv2.THRESH_BINARY_INV)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83268751",
   "metadata": {},
   "source": [
    "OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29d08695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text: Q11. How does prompt engineering influence the output of LLMs?\n",
      "\n",
      "Ans - Prompt engineering involves crafting input prompts to guide an\n",
      "LLMâ€™s output effectively. Since LLMs are highly sensitive to input\n",
      "phrasing, a well-designed prompt can significantly influence the\n",
      "quality and relevance of the response. For example, adding context\n",
      "or specific instructions within the prompt can improve accuracy in\n",
      "tasks like summarization or question-answering. Prompt engineering\n",
      "is especially useful in zero-shot and few-shot learning scenarios,\n",
      "where task-specific examples are minimal.\n",
      "\n",
      "The Cycle of Prompt Engineering\n",
      "\n",
      "Design Prampt\n",
      "\n",
      "Refine Prompt Submit to LLM\n",
      "\n",
      "wo Foc Output\n",
      "Output\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = pytesseract.image_to_string(thresh)\n",
    "print(\"Extracted Text:\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb6a38e",
   "metadata": {},
   "source": [
    "Automatic Document Scanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "113ed476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bcdb5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and resize image\n",
    "image = cv2.imread(\"paper.jpeg\")\n",
    "if image is None:\n",
    "    print(\"Error: Image not loaded. Check file path.\")\n",
    "    exit()\n",
    "orig = image.copy()\n",
    "image = imutils.resize(image, height=600) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6189422a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "# thresholding for uneven lighting\n",
    "thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                              cv2.THRESH_BINARY_INV, 11, 2)\n",
    "edged = cv2.Canny(thresh, 50, 150)  # Adjusted Canny thresholds\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c7e3b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of contours: 10\n"
     ]
    }
   ],
   "source": [
    "# Find contours\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:10]  # Top 10 contours\n",
    "print(f\"Number of contours: {len(cnts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb65b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Detect document contour\n",
    "doc_cnt = None\n",
    "for c in cnts:\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "    if len(approx) == 4:\n",
    "        doc_cnt = approx\n",
    "        cv2.drawContours(image, [doc_cnt], -1, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Detected Contour\", image)\n",
    "        cv2.waitKey(0)\n",
    "        break\n",
    "\n",
    "if doc_cnt is None:\n",
    "    print(\"No quadrilateral detected. Adjust image or parameters.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acbcaac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perspective transform\n",
    "warped = four_point_transform(orig, doc_cnt.reshape(4, 2))\n",
    "\n",
    "# Resize for display and save\n",
    "scanned = imutils.resize(warped, height=800)\n",
    "cv2.imshow(\"Scanned\", scanned)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"scanned_document.jpg\", scanned)  # Save the output\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "905a26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]  # top-left\n",
    "    rect[2] = pts[np.argmax(s)]  # bottom-right\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]  # top-right\n",
    "    rect[3] = pts[np.argmax(diff)]  # bottom-left\n",
    "    return rect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52d11ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_point_transform(image, pts):\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    widthA = np.linalg.norm(br - bl)\n",
    "    widthB = np.linalg.norm(tr - tl)\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "    heightA = np.linalg.norm(tr - br)\n",
    "    heightB = np.linalg.norm(tl - bl)\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    dst = np.array([[0, 0], [maxWidth - 1, 0], [maxWidth - 1, maxHeight - 1], [0, maxHeight - 1]], dtype=\"float32\")\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d6102c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
